# -*- coding: utf-8 -*-
"""LVADSUSR166_Final_AnomalyDetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VPvQ9210lw-fG7-N_X5FdCW1TV4cB8zB
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, StandardScaler

# 1 Loading the dataset
df = pd.read_csv(r"/content/anomaly_train.csv")

df.info()

# 2 Preprocessing
# 3 EDA
# both start here
df.head()

df.isnull().sum()

# Since there are no null values we don't need to work on removing them

df.duplicated().sum()

# Since there are no duplicate values, we don't need to work on removing them

df.describe()

df.describe(include = 'all')

df.shape

label_encoder = LabelEncoder()
categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

corr_matrix=df.drop(['TransactionID', 'User'], axis=1).corr()
sns.heatmap(corr_matrix,annot=True,fmt=".2f",cmap='viridis')
plt.show()

# Select the features to be used for anomaly detection
features = ["Amount", "Type", "Time", "Location"]

# Creating New DF
X = df[features]

# 4 MODEL TRAINING: Fitting an Isolation Forest model onto the data
model = IsolationForest(n_estimators=100, contamination=0.1)
model.fit(X)

# Predict the anomalies in the data
y_pred = model.predict(X)

y_pred

# Add the predicted anomaly scores to the original dataframe
df["anomaly_score"] = model.decision_function(X)

df.head()

anomalies = df.loc[df["anomaly_score"] < 0]

anomalies

# 5 Evaluation Metrics
plt.scatter(df["Amount"], df["anomaly_score"], label="Normal")
plt.scatter(anomalies["Amount"], anomalies["anomaly_score"], color="r", label="Anomaly")
plt.xlabel("Amount")
plt.ylabel("anomaly_score")
plt.legend()
plt.show()